# Docker에서 GPU 사용하기
오늘은 Docker container에서 gpu를 사용하는 방법에 대해서 공부하였다.
Docker자체로는 gpu사용을 제공하지 않기 때문에, nvidia-docker를 설치해서 gpu를 사용하고자 한다.

## (1) Docker에서 pytorch 이미지 실행하기

```
sudo docker run -it pytorch/pytorch:1.4-cuda10.1-cudnn7-devel bash % -it는 bash 입출력을 위한 인자
```

하지만 이렇게 docker container를 실행시키면 gpu를 사용할 수 없다.

![image](https://github.com/Bosung-Yang/DeepLearning/assets/139629920/18be1c26-b487-48b4-b2fe-9515b6ebbf6e)

왜냐하면 nvidia driver는 docker보다 low-level에서 동작하기 때문에, docker container들은 gpu 자원에 대한 정보를 알지 못한채 가상화되기 때문이다.

따라서, docker container가 gpu를 사용하기 위해서는 nvidia-docker를 사용하여야 한다.

## (2) Nvidia-docker 설치하기
nvidia-docker는 apt를 동해 다운로드 받을 수 있다.

```
sudo apt-get update
sudo apt-get install nvidia-docker2 -y
```
여기서 유의할점은 패키지 명이 nvidia-docker가 아니라 nvidia-docker2라는 것이다.

nvidia-docker2를 다운받았으면, 적용을 위해서 docker를 재시작해야한다.

```
sudo systemctl restart docker
```

하지만 nvidia-docker를 다운받기만 해서는 gpu를 바로 사용할 수는 없다. (1)에 기술된 대로 container를 시작하게 되면, 여전히 torch.cuda.is_available()는 False라는 결과를 가져온다.

container가 gpu를 사용하기 위해서는 docker 실행시 runtime 옵션을 넣어주어야 한다.

```
docker run -it --runtime=nvidia pytorch/pytorch:1.4-cuda10.1-cudnn7-devel bash
```

그 결과, pytorch에서 gpu를 사용할 수 있는 설정이 완료된다.
![image](https://github.com/Bosung-Yang/DeepLearning/assets/139629920/a66fd7d6-fe1a-47d3-9a83-bd3872dbd646)

다음 포스트에서는 나만의 모델 동작 환경을 만들 수 있는 custom docker 이미지 제작에 대해서 다루고자 한다.
